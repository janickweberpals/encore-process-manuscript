---
title: "A Process for the Emulation of Comparative Oncology Trials with Real-world Evidence (ENCORE)"

code-fold: false
echo: false
number-sections: false
warnings: false
messages: false

format: 
  docx:
    fig-cap-location: top
    tbl-cap-location: top
    reference-doc: custom-reference-doc.docx
  pdf:
    include-in-header: 
      text: |
        \usepackage{lscape}
        \newcommand{\blandscape}{\begin{landscape}}
        \newcommand{\elandscape}{\end{landscape}}
    fig-cap-location: top
    tbl-cap-location: top
    
editor: visual
bibliography: references.bib
csl: journal-of-clinical-oncology.csl

filters:
  - docx-landscape.lua
---

```{r}
#| label: setup
#| include: false

library(here)
library(dplyr)
library(knitr)
library(gt)
library(readxl)
library(fs)
library(webshot2)
library(tibble)
library(ggplot2)
library(cowplot)
```

**Authors**: Janick Weberpals^1^, Kenneth L. Kehl^2^, Donna R. Rivera^3^, ..., Sebastian Schneeweiss^1^, Shirley V. Wang^1^

[Author affiliations:]{.underline}

^1^ Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, USA

^2^ Dana-Farber, ..., USA

^3^ Oncology Center of Excellence, US Food and Drug Administration, Silver Spring, MD, USA

[**Correspondence:**]{.underline}

Shirley V. Wang, PhD

Division of Pharmacoepidemiology and Pharmacoeconomics,

Department of Medicine, Brigham and Women's Hospital, Harvard Medical School,

1620 Tremont Street, Suite 3030-R, Boston, MA 02120, USA

Phone: +1 617-278-0932

Fax: + 1 617-232-8602

Email: [SWANG1\@BWH.HARVARD.EDU](SWANG1@BWH.HARVARD.EDU)

[**Article type:**]{.underline} Review

[**Word count:**]{.underline} xxx words / xxx words

[**Tables:**]{.underline} x

[**Figures:**]{.underline} x

[**Supplementary material:**]{.underline} Supplementary tables and figures

[**Short running title**]{.underline}: ...

[**Keywords:**]{.underline} Oncology, Real-World Evidence, Trial emulation, EHR

[**Funding Statement:**]{.underline} This project was supported by ...

[**Competing Interests Statement:**]{.underline} Dr. Weberpals is now an employee of AstraZeneca and owns stocks in AstraZeneca. Dr. Wang has consulted ad hoc for Exponent Inc. and MITRE a federally funded research center for the Centers for Medicare and Medicaid Services on unrelated work. Dr. Schneeweiss is participating in investigator-initiated grants to the Brigham and Women's Hospital from Boehringer Ingelheim, Takeda, and UCB unrelated to the topic of this study. He owns equity in Aetion Inc., a software manufacturer. He is an advisor to Temedica GmbH, a patient-oriented data generation company. His interests were declared, reviewed, and approved by the Brigham and Women's Hospital in accordance with their institutional compliance policies.

[**Data sharing statement:**]{.underline} ...

[**Analytic code sharing statement:**]{.underline} ...

[***Proposed target journals:***]{.underline} *JCO CCI =\> JAMA Network Open =\> CPT*

*Manuscript last updated: `r Sys.time()`*

{{< pagebreak >}}

# Abstract {.unnumbered}

xxx words/xxx words

...

{{< pagebreak >}}

# Background

Randomized controlled trials (RCTs) have been the gold standard for establishing the efficacy and safety of medical products. With the advent of the the 21^st^ Century Cures Act directive[@RWEFDA], the Food and Drug Administration (FDA) established a framework to increasingly consider real-world evidence (RWE) generated from routine-care health data such as electronic health records (EHR) to evaluate and contextualize the comparative safety and effectiveness of novel cancer therapies.[@purpura2022role] With 21% of all approvals, oncology was the disease area with the most FDA drug approvals in 2023,[@senior2024fresh] and especially in the field of precision oncology, RWE has a large potential to complement evidence coming from RCTs. Potential use cases comprise the assessment of effectiveness in patient populations that are underrepresented in RCTs, the construction of external control arms in single-arm trials where active recruitment may not be feasible or the discovery of biomarkers among pan-tumor populations that harbor specific genomic and immuno-pathological signatures.

However, the validity and transportability of results derived betwen RWE studies and RCTs can depend on many factors and frequently referenced limitations include missing data, small sample sizes, data discontinuity [@Merola2022; @joshua2022longitudinal], rapid changes in guideline treatment patterns and the inability to measure and emulate common eligibility criteria and prognostic factors in real-world data (RWD).[@rider2024emulations] While there are already published examples of oncology trial emulations[@rider2024emulations; @merola2023aetion; @merola2024calibrating], a systematic and scaled approach to emulate a diverse set of different oncology trials in various heterogeneous databases is necessary to gain confidence in the accuracy of RWE studies and to provide an answer as to which questions can be validly answered.

The RCT DUPLICATE initiative[@wang2023emulation] increased our understanding of when RWE studies can come to causal conclusions on treatment effects by comparing results against RCTs under the assumption that each RCT finding reflects a causal treatment effect. In settings where the RCT designs could be emulated well, RWE studies came to the same conclusions.[@heyard2024design] However, prior work from RCT-DUPLICATE has focused primarily on emulating trials in the cardio-metabolic, renal, and pulmonary clinical areas using claims databases.

The *Emulation of Comparative Oncology Trials with Real-world Evidence* (**ENCORE**) project [@encoreFDA] aims to extend this work to the field of oncology which comes with its own unique set of challenges which must be systematically explored and understood. Building on a process co-developed with the FDA through RCT DUPLICATE[@wang2023emulation], this expansion to oncology is going to emulate 12 randomized clinical trials using multiple EHR data sources. The process includes an emphasis on transparency with documented assessment of data fitness of the RWD source for each trial[@rivera2024oncology; @gatto2022structured] and the conduct of extensive sensitivity analyses to assess robustness of findings and trial eligibility criteria.

The objectives of this project are to develop state-of-the-art methodological approaches and apply these to create insights that may provide guidance on the potential use of RWE for regulatory science in oncology. This includes the systematic evaluation of the suitability of data in relation to the study design and statistical analysis by emulating 12 oncology trials across four cancers and assessing the agreement of treatment effect estimates between RCTs and their respective emulations.

In this process paper, we describe the design and process for the selection of the 12 oncology RCTs, the assessment of the database quality and selection, protocol development, study design and statistical analysis and final agreement metrics to evaluate the concordance between RCTs and emulations.

# Methods

A visual summary of the entire systematic process from trial selection to final results is provided in @fig-process.

## Trial selection

The focus of ENCORE is to maximize potential learnings on when RWE studies can or cannot yield similar results compared to RCTs. To that end, the emphasis of the project is on trials of therapies for the most common cancers and/or cancers for which there has been substantial therapeutic development in recent years. After careful review and exchange with clinical and regulatory experts, four cancer indications were identified including lung cancer, breast cancer, colorectal cancer and multiple myeloma. For each cancer we aim to conduct three trial emulations which will be implemented using multiple databases accessible for the scope of this project (i.e. the total number of emulations will equal 12 trials x *n* databases which are found fit-for-purpose for each trial).

The trial selection will follow a semi-automated process for which we will document the eligibility criteria resulting in a CONSORT diagram showing reasons for excluding RCTs. The search will be conducted using the AACT database which is s a publicly available relational database developed and maintained by the Clinical Trials Transformation Initiative (CTTI) which contains all information (protocol and result data elements) about every study registered on ClinicalTrials.gov.[@tasneem2012database] To identify eligible trials, we will use a combined search query strategy of the National Library of Medicine (NLM)-controlled *MeSH* term and a free keyword search for the respective cancer indication in the *conditions*, *studies* and *detailed_descriptions* fields of each trial entry on ClinicalTrials.gov.

Eligible trials need to fulfill the following basic criteria:

-   Interventional

-   Randomized

-   Intervention model: parallel assignment

-   Industry-sponsored

-   Trial start in 2011 or later

-   Primary purpose was to study treatment effects

-   Overall survival must be one of the endpoints reported

-   Recruitment status: ‘Completed’ or ‘Active, not recruiting’

-   Feasibility and clinical relevance

The rationale and operationalization of each criterion is listed in detail in @tbl-criteria. We will mainly consider pivotal interventional, randomized trials after 2011 since treatment guidelines among studied cancer indications have undergone significant changes in recent years. Due to the rapid adoption of new breakthrough therapies in routine care, it is unlikely to find patients who may be still treated with outdated treatment regimens in the real-world. In parallel, trial results should have also not been published too recently in order to allow for enough data and follow-up time accrual in databases used for this project. An further focus is on trials that have reported overall survival (OS) as one of the pre-specified endpoints in the protocol. Although there have been substantial methodological advancements to increase our understanding on the emulation and comparison of real-world progression-free survival (PFS) and objective response rates (ORR) to a RECISTv1.1[@eisenhauer2009new]-based PFS and ORR assessment in RCTs [@ThanCCR;@mckelvey2024evaluation], imaging-based evaluations still hold a level of granularity which may not be necessarily reflected in chart-abstracted assessments of a patient's progression in routine care.[@rwdRECIST;@rivera2022friends] Given the large number of other methodological challenges like missing data, small sample sizes, data discontinuity and rapidly changing guideline treatments, the scope of this project was to focus on the emulation of OS as the endpoint of interest.

While most trial-eligibility criteria can be operationalized in an automated fashion, the last criterion on emulation feasibility and clinical relevance involves extensive human review. The critical points considered in this step include a thorough feasibility assessment of the data fitness [@rivera2022friends], sample size considerations and the assessment if critical eligibility criteria (e.g., biomarker status) and prognostic factors (e.g., ECOG performance score) are measurable and can be balanced using propensity score matching or weighting methods.[@brookhart2006variable] Lastly, trial candidates are ranked and shortlisted into primary and runner-up candidates based on their clinical and regulatory relevance.

A list of tentative, shortlisted primary candidates is presented in @tbl-rcts and the corresponding selection process is illustrated in the CONSORT diagrams (Supplementary Figures 1-4). Naturally, the majority trials will cover advanced or metastatic cancer populations since a large proportion of drug development efforts have focused on these settings in recent years. A key learning that we aim to foster with the shortlisted trials is to achieve a better understanding how different disease settings (early, late), line settings (\[neo\]adjuvant, first line, advanced lines of therapy), therapy protocols (monotherapy, combination therapy) and population characteristics (simple versus complex genetic or immunological signatures) can be emulated using RWD. If ongoing feasibility assessments indicate that these trials cannot be emulated with high enough confidence, runner-up candidates will be considered instead.

## Databases

The ENCORE project will utilize data from a total four different oncology-specific electronic health records (EHR)-derived data sources: ConcertAI, COTA, Flatiron Health, McKesson/Ontada. All available databases draw from a comprehensive national sample of patients with cancer in the US with detailed EHR-derived information on the information necessary to study medication effectiveness in oncology. For ENCORE, not all databases will be available for each cancer indication and the names of the databases will be blinded and referred to as ENCORE DataBase (EDB) 1, 2, 3 and 4 for the final reporting of results. If more than one database is considered fit-for-purpose for a respective trial emulation, the best possible analytic model will be employed for each database separately and final treatment effect estimates will be pooled using a meta-analytic approach.

## Protocol development

For each shortlisted and selected RCT, a detailed protocol, pre-specifying key elements of the trial emulation, will be developed following the HARPER protocol template[@wang2022harmonized] and registered on ClinicalTrials.gov. Following the target trial emulation framework, we will provide an explicit statement and rationale on how each element will be emulated including database selection, covariate measurement, operationalization of key eligibility criteria, study design, data analysis and causal contrasts of interest.[@hernan2022target; @hernan2016specifying] Since it is common that oncology RCTs update OS estimates periodically based on accrued follow-up time, the protocol will give a brief summary of each emulated RCT and specify which target OS estimates will be used to compare agreement metrics to. All eligibility criteria will be extracted based on publicly available protocols and statistical analysis plans of the selcted RCT. According to the *Structured Process to Identify Fit-For-Purpose Data* (SPIFD) framework[@gatto2022structured], tables will outline how eligibility criteria will be measured and operationalized and a color-coded heatmap will indicate the level of confidence on how well each criterion can be emulated in each selected database. As there are general eligibility criteria in oncology trials which either won't be possible to emulate (e.g., physician-assessed survival prognosis of xy months) or that are clinically not relevant for the emulation of the trial (e.g., male patients should be willing to use barrier contraception), the study team will decide on key eligibility criteria for the emulation of the trial. We will additionally provide a definition on how exposure and outcomes are defined and ascertained in each respective database. For the considered databases, the OS endpoint is a composite that is derived from different sources like EHR flags, social security death index, obituary and other linkages. Given that not all relevant sources that provide mortality data are synchronized and updated uniformly, sensitivity analyses with more conservative (i.e., earlier) censoring dates will be considered for each trial emulation to mitigate the potential impact of ghost-time bias.[@meyer2020open] Each final protocol draft will be reviewed by a clinical and FDA regulatory expert panel before registration on ClinicalTrials.gov.

Critical aspects when emulating oncology trials are the choice and estimation of the approriate estimand of interest.[@rufibach2018] Particularly when emulating pivotal trials of paradigm-changing treatments, multiple aspects need to be considered such as the contemporaneity of the (historical) control cohort, the adoption rate of the novel intervention in routine care, the magnitude of the clinical treatment benefit and the rate in which (particularly patients in the control arm) discontinue or cross-over to the interventional treatment, which could lastly bias emulated treatment effects towards the null. To that end, comprehensive diagnostics will be performed to contextualize these parameters and (if reported) draw comparisons to the emulated trial.

## gn and statistical analysis

[@weberpals2024]

## Agreement metrics

{{< pagebreak >}}

# Discussion

...

## Conclusions

...

{{< pagebreak >}}

# References {.unnumbered}

::: {#refs}
:::

{{< pagebreak >}}

# Tables {.unnumbered}

```{r}
#| label: tbl-criteria
#| tbl-cap: "Criteria to select eligible trials for emulation in ENCORE."
#| tbl-cap-location: top

# read excel blueprint
eligibility_criteria <- read_excel(
  path = here("tables", "helper_tables.xlsx"),
  sheet = "ctgov_criteria_defintions"
  )

# convert to gt table
tbl_eligibility_criteria <- eligibility_criteria |> 
  select(-Link) |> 
  filter(Criteria != "Study phase") |> 
  gt() |> 
  tab_style(
    style = cell_text(weight = "bold"),
      locations = cells_column_labels()
    )

# save table as .docx document
tbl_eligibility_criteria |> 
   gtsave(
    filename = here("manuscript", "Table_1_trial_eligibility.docx")
    )

# save image to display within manuscript document
tbl_eligibility_criteria |> 
  gtsave(
    filename = here("tables", "Table_1_trial_eligibility.png"),
    expand = 10, # amount of whitespace,
    zoom = 5 # higher resolution
    )

include_graphics(path = here("tables", "Table_1_trial_eligibility.png"))
```

{{< pagebreak >}}

```{r}
#| label: tbl-rcts
#| tbl-cap: "Tentative list of randomized controlled trials (RCTs) considered for emulation."
#| tbl-cap-location: top

rct_selection <- read_excel(
  path = here("tables", "helper_tables.xlsx"),
  sheet = "rct_selection"
  )

tbl_rct_selection <- rct_selection |> 
  group_by(cancer) |> 
  gt() |> 
  cols_label(
    nctid = md("**NCTID**"),
    acronym = md("**Acronym**"),
    setting = md("**Clinical setting**"),
    line = md("**Line of therapy**"),
    exposures = md("**Treatment comparison**")
    ) |> 
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
    )

# save table as .docx document
tbl_rct_selection |> 
   gtsave(
    filename = here("manuscript", "Table_2_trial_selection.docx")
    )

# save image to display within manuscript document
tbl_rct_selection |> 
  gtsave(
    filename = here("tables", "Table_2_trial_selection.png"),
    expand = 10, # amount of whitespace,
    zoom = 5 # higher resolution
    )

include_graphics(path = here("tables", "Table_2_trial_selection.png"))
```

{{< pagebreak >}}

# Figures {.unnumbered}

```{r}
#| label: fig-process
#| fig-cap: "Systematic process to understand effectiveness claims of oncology trials using real-world evidence."
#| fig-cap-location: top
#| fig-width: 12

knitr::include_graphics(here("figures", "process.png"))

# copy figure to manuscript
file_copy(
  path = here("figures", "process.png"),
  new_path = here("manuscript", "Figure_1_process.png"),
  overwrite = TRUE
  )
```

[View figure in higher resolution here](https://github.com/janickweberpals/encore-process-manuscript/blob/main/figures/process.png)

{{< pagebreak >}}

```{r}
#| label: fig-initiators
#| fig-cap: "Descriptive drug utilization analyses."
#| fig-widh: 4
#| fig-height: 7
#| warnings: false

data <- tibble::tibble(
  drug = c(rep("Drug A", 5), rep("Drug B", 5)),
  initiators = c(0, 220, 300, 399, 500, 456, 400, 278, 180, 35),
  year = rep(c(2011, 2012, 2013, 2014, 2015), 2)
  ) 

initiators <- data |> 
  ggplot(aes(x = year, y = initiators, group = drug, color = drug)) +
  geom_line(linewidth = 1) +
  labs(
    x = "Calendar Year",
    y = "# initiators",
    color = "Exposure"
    ) +
  scale_color_manual(values=c('orange','blue')) +
  theme_minimal(base_size = 10)

# treatment switch
data <- tibble::tibble(
  drug = c(rep("Drug A", 6), rep("Drug B", 6)),
  prop = c(4.1, 7.7, 17.7, 22.2, 24.4, 24.5, 4.6, 13.2, 25.1, 29, 29.3, 31.3),
  time = rep(seq(1, 12, 2), 2)
  ) 

switchers <- data |> 
  ggplot(aes(x = time, y = prop, group = drug, color = drug)) +
  geom_line(linewidth = 1) +
  labs(
    x = "Follow-up time [Months]",
    y = "Cumulative switch rate",
    color = "Exposure"
    ) +
  scale_color_manual(values=c('orange','blue')) +
  theme_minimal(base_size = 10)

# combine plots with shared legend
shared_legend <- get_legend(initiators)

plot_utilization <- plot_grid(
  plot_grid(initiators + theme(legend.position = "top")),
  plot_grid(switchers + theme(legend.position = "none")),
  ncol = 1,
  nrow = 2,
  labels = c("a)", "b)"),
  shared_legend
  )

# save
ggsave(
  plot = plot_utilization,
  filename = "Figure_2_utlization.png",
  path = here("manuscript"),
  dpi = 800)

# print to manuscript
include_graphics(path = here("manuscript", "Figure_2_utlization.png"))
```
